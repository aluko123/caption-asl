setting asax scratch directory
 
============================================================
=====         Summary of your script job               =====
============================================================
  The script file is: run_analysis.sh
  The time limit is 4:00:00 HH:MM:SS.
  The target directory is: /home/uahoxa001/WLASL/start_kit
  The working directory is:  /scratch-local/uahoxa001.parallel1.92053.asax-pbs1
  The memory limit is: 16gb
  The job will start running after: 202407151330.23
  Job Name: parallel1
  Queue: -q express
  Constraints: 
  Using  2  cores on master node  asax002.asc.edu
  Node list:  asax002.asc.edu asax002.asc.edu
  Cores:  2
  Command typed:
/scripts/run_script run_analysis.sh     
  Queue submit command:
qsub -q express -j oe -N parallel1 -a 202407151330.23 -r n -M oaa0008@uah.edu -l walltime=4:00:00 -l select=ncpus=2:mpiprocs=2:mem=16000mb 
/apps/x86-64/apps/anaconda_3-2024.02/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
[nltk_data] Downloading package punkt to /home/uahoxa001/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt.zip.
[nltk_data] Error loading average_perceptron_tagger: Package
[nltk_data]     'average_perceptron_tagger' not found in index
Top 10 most common signs:
thin: 15
go: 14
computer: 13
before: 13
help: 13
cool: 13
bowling: 13
drink: 12
thanksgiving: 12
bed: 12
Cluster 0: ['too', 'one', 'all', 'just', 'a']
Cluster 1: ['brown', 'water', 'pants', 'chicken', 'car']
Cluster 2: ['school', 'town', 'city', 'thing', 'house']
Cluster 3: ['go', 'make', 'take', 'get', 'bring']
Cluster 4: ['america', 'europe', 'england', 'usa', 'france']

Most similar signs:
Signs similar to 'book': ['books', 'author', 'memoir', 'Book', 'tome']
Signs similar to 'drink': ['drinks', 'drinking', 'Drink', 'beverage', 'drank']
Signs similar to 'computer': ['computers', 'Computer', 'software', 'laptop', 'computing']
Traceback (most recent call last):
  File "/home/uahoxa001/WLASL/start_kit/parallel_dataset.py", line 35, in <module>
    english = generate_simple_sentence(gloss)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/uahoxa001/WLASL/start_kit/parallel_dataset.py", line 14, in generate_simple_sentence
    tagged = nltk.pos_tag(words)
             ^^^^^^^^^^^^^^^^^^^
  File "/apps/x86-64/apps/anaconda_3-2024.02/lib/python3.11/site-packages/nltk/tag/__init__.py", line 165, in pos_tag
    tagger = _get_tagger(lang)
             ^^^^^^^^^^^^^^^^^
  File "/apps/x86-64/apps/anaconda_3-2024.02/lib/python3.11/site-packages/nltk/tag/__init__.py", line 107, in _get_tagger
    tagger = PerceptronTagger()
             ^^^^^^^^^^^^^^^^^^
  File "/apps/x86-64/apps/anaconda_3-2024.02/lib/python3.11/site-packages/nltk/tag/perceptron.py", line 167, in __init__
    find("taggers/averaged_perceptron_tagger/" + PICKLE)
  File "/apps/x86-64/apps/anaconda_3-2024.02/lib/python3.11/site-packages/nltk/data.py", line 583, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93maveraged_perceptron_tagger[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('averaged_perceptron_tagger')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle[0m

  Searched in:
    - '/home/uahoxa001/nltk_data'
    - '/apps/x86-64/apps/anaconda_3-2024.02/nltk_data'
    - '/apps/x86-64/apps/anaconda_3-2024.02/share/nltk_data'
    - '/apps/x86-64/apps/anaconda_3-2024.02/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

